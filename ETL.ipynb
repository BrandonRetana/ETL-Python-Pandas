{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d3e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import ltrim,rtrim,trim,col\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "spark = SparkSession.builder.appName(\"MyFirstCSV\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5739b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#CREATE DATAFRAME FROM CSV FILE\n",
    "oij_df = spark.read.csv( path=\"OIJ.csv\", sep=\",\", header=True,quote='\"',inferSchema=True,)\n",
    "inec_df = spark.read.csv( path=\"INEC.csv\", sep=\";\", header=True,quote='\"',inferSchema=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29dfe503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 19:50:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Delito, SubDelito, Fecha, Hora, Victima, SubVictima, Edad, Genero, Nacionalidad, Provincia, Canton, Distrito, \n",
      " Schema: Delito, SubDelito, Fecha, Hora, Victima, SubVictima, Edad, Genero, Nacionalidad, Provincia, Canton, Distrito, _c12\n",
      "Expected: _c12 but found: \n",
      "CSV file: file:///mnt/c/Users/kevin/desktop/proyecto3bases/ProyectoBases3/OIJ.csv\n",
      "+------+-----------+-------------------+-------------------+--------+--------------------+-------------+------+------------+----------+----------+--------+----+\n",
      "|Delito|  SubDelito|              Fecha|               Hora| Victima|          SubVictima|         Edad|Genero|Nacionalidad| Provincia|    Canton|Distrito|_c12|\n",
      "+------+-----------+-------------------+-------------------+--------+--------------------+-------------+------+------------+----------+----------+--------+----+\n",
      "|ASALTO|ARMA BLANCA|2021-06-03 00:00:00|00:00:00 - 02:59:59|VEHICULO|SERVICIO PUBLICO/...|Mayor de edad|HOMBRE|  COSTA RICA|  san jose|alajuelita|    null|null|\n",
      "|ASALTO|ARMA BLANCA|2021-06-10 00:00:00|15:00:00 - 17:59:59| PERSONA|    PEATON [PERSONA]|Mayor de edad| MUJER|  COSTA RICA|  san jose|    escazu|    null|null|\n",
      "|ASALTO|ARMA BLANCA|2021-06-14 00:00:00|09:00:00 - 11:59:59| PERSONA|    PEATON [PERSONA]|Mayor de edad|HOMBRE|  COSTA RICA|guanacaste|    nicoya|    null|null|\n",
      "|ASALTO|ARMA BLANCA|2021-06-14 00:00:00|15:00:00 - 17:59:59| PERSONA|    PEATON [PERSONA]|Mayor de edad|HOMBRE|   NICARAGUA|   cartago|   cartago|    null|null|\n",
      "|ASALTO|ARMA BLANCA|2021-06-15 00:00:00|21:00:00 - 23:59:59| PERSONA|    PEATON [PERSONA]|Mayor de edad|HOMBRE|   NICARAGUA|  san jose|  san jose|    null|null|\n",
      "+------+-----------+-------------------+-------------------+--------+--------------------+-------------+------+------------+----------+----------+--------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------------------+--------------------------+--------------------------+-----------------+-------------------------+-----------------------------------------------+---------------------------------+\n",
      "|Provincia, cantón y distrito|Población de 15 años y más|Tasa neta de participación|Tasa de ocupación|Tasa de desempleo abierto|Porcentaje de población económicamente inactiva|Relación de dependencia económica|\n",
      "+----------------------------+--------------------------+--------------------------+-----------------+-------------------------+-----------------------------------------------+---------------------------------+\n",
      "|                        null|                      null|                      null|             null|                     null|                                           null|                             null|\n",
      "|                    san josé|                 1 087 315|                        56|             54,1|                      3,5|                                             44|                              1,3|\n",
      "|                        null|                      null|                      null|             null|                     null|                                           null|                             null|\n",
      "|                    san josé|                   225 856|                      56,7|             54,5|                      3,9|                                           43,3|                              1,2|\n",
      "|                        null|                      null|                      null|             null|                     null|                                           null|                             null|\n",
      "+----------------------------+--------------------------+--------------------------+-----------------+-------------------------+-----------------------------------------------+---------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Function to remove spaces from the beginning and end of the string\n",
    "def remove_spaces(df):\n",
    "    for col in df.columns:\n",
    "        if  col == 'Provincia' or col == 'Canton' or col == 'Distrito' or col == 'Provincia, cantón y distrito':\n",
    "            df = df.withColumn(col, trim(col))\n",
    "    return df\n",
    "\n",
    "#Function to parser the string to lowercase\n",
    "def to_lower_case(df):\n",
    "    for col in df.columns:\n",
    "        if  col == 'Provincia' or col == 'Canton' or col == 'Distrito' or col == 'Provincia, cantón y distrito':\n",
    "            df = df.withColumn(col, lower(col))\n",
    "    return df\n",
    "\n",
    "\n",
    "oij_df = remove_spaces(oij_df)\n",
    "inec_df = remove_spaces(inec_df)\n",
    "\n",
    "oij_df = to_lower_case(oij_df)\n",
    "inec_df = to_lower_case(inec_df)\n",
    "\n",
    "oij_df.show(5)\n",
    "inec_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf9bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function find list the not match values in the dataframes\n",
    "def find_non_matches(df1,df2):\n",
    "    non_matches = []\n",
    "    for col in df1.columns:\n",
    "        if  col == 'Provincia' or col == 'Canton' or col == 'Distrito':\n",
    "            for row in df1.select(col).distinct().collect():\n",
    "                if not df2.filter(df2['Provincia, cantón y distrito'] == row[col]).collect():\n",
    "                    non_matches.append(row[col])\n",
    "    return non_matches\n",
    "\n",
    "non_matches_oij = find_non_matches(oij_df,inec_df)\n",
    "\n",
    "\n",
    "#Function to parser the string to lowercase\n",
    "def to_lower_case(df):\n",
    "    for col in df.columns:\n",
    "        if  col == 'Provincia' or col == 'Canton' or col == 'Distrito' or col == 'Provincia, cantón y distrito':\n",
    "            df = df.withColumn(col, lower(col))\n",
    "    return df\n",
    "\n",
    "\n",
    "oij_df = remove_spaces(oij_df)\n",
    "inec_df = remove_spaces(inec_df)\n",
    "\n",
    "oij_df = to_lower_case(oij_df)\n",
    "inec_df = to_lower_case(inec_df)\n",
    "\n",
    "nonMatches = find_non_matches(oij_df,inec_df)\n",
    "print(nonMatches)\n",
    "#oij_df.show(5)\n",
    "#inec_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to replace the accents in column Provincia, cantón y distrito in inec_df\n",
    "def replace_accents(df):\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'á', 'a'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'é', 'e'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'í', 'i'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'ó', 'o'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'ú', 'u'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'ñ', 'n'))\n",
    "    return df\n",
    "\n",
    "inec_df = replace_accents(inec_df)\n",
    "nonMatches = find_non_matches(oij_df,inec_df)\n",
    "print(nonMatches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e476025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fucntion to separate column Provincia, cantón y distrito in inec_df in three columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ffe418",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can not infer schema from empty dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m             new_df \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39munion(spark\u001b[39m.\u001b[39mcreateDataFrame([(Provincia, Canton, row[\u001b[39m2\u001b[39m], row[\u001b[39m3\u001b[39m], row[\u001b[39m4\u001b[39m], row[\u001b[39m5\u001b[39m])], columns))\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m new_df\n\u001b[0;32m---> 21\u001b[0m generate_new_columns(inec_df)\n",
      "Cell \u001b[0;32mIn [8], line 3\u001b[0m, in \u001b[0;36mgenerate_new_columns\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_new_columns\u001b[39m(df):\n\u001b[1;32m      2\u001b[0m     columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mProvincia\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCanton\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDistrito\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mTasa neta de participación\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPorcentaje de población económicamente inactiva\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRelación de dependencia económica\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m     new_df \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39;49mcreateDataFrame(data \u001b[39m=\u001b[39;49m[], schema \u001b[39m=\u001b[39;49m columns)\n\u001b[1;32m      4\u001b[0m     Provincia \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      5\u001b[0m     Canton \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/session.py:894\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[39mif\u001b[39;00m has_pandas \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(data, pandas\u001b[39m.\u001b[39mDataFrame):\n\u001b[1;32m    890\u001b[0m     \u001b[39m# Create a DataFrame from pandas DataFrame.\u001b[39m\n\u001b[1;32m    891\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(SparkSession, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mcreateDataFrame(  \u001b[39m# type: ignore[call-overload]\u001b[39m\n\u001b[1;32m    892\u001b[0m         data, schema, samplingRatio, verifySchema\n\u001b[1;32m    893\u001b[0m     )\n\u001b[0;32m--> 894\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dataframe(\n\u001b[1;32m    895\u001b[0m     data, schema, samplingRatio, verifySchema  \u001b[39m# type: ignore[arg-type]\u001b[39;49m\n\u001b[1;32m    896\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/session.py:936\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    934\u001b[0m     rdd, struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_createFromRDD(data\u001b[39m.\u001b[39mmap(prepare), schema, samplingRatio)\n\u001b[1;32m    935\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     rdd, struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_createFromLocal(\u001b[39mmap\u001b[39;49m(prepare, data), schema)\n\u001b[1;32m    937\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    938\u001b[0m jrdd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jvm\u001b[39m.\u001b[39mSerDeUtil\u001b[39m.\u001b[39mtoJavaArray(rdd\u001b[39m.\u001b[39m_to_java_object_rdd())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/session.py:631\u001b[0m, in \u001b[0;36mSparkSession._createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m    628\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data)\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m schema \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(schema, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m--> 631\u001b[0m     struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inferSchemaFromList(data, names\u001b[39m=\u001b[39;49mschema)\n\u001b[1;32m    632\u001b[0m     converter \u001b[39m=\u001b[39m _create_converter(struct)\n\u001b[1;32m    633\u001b[0m     tupled_data: Iterable[Tuple] \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(converter, data)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/session.py:514\u001b[0m, in \u001b[0;36mSparkSession._inferSchemaFromList\u001b[0;34m(self, data, names)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    500\u001b[0m \u001b[39mInfer schema from list of Row, dict, or tuple.\u001b[39m\n\u001b[1;32m    501\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[39m:class:`pyspark.sql.types.StructType`\u001b[39m\n\u001b[1;32m    512\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    513\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[0;32m--> 514\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcan not infer schema from empty dataset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    515\u001b[0m infer_dict_as_struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jconf\u001b[39m.\u001b[39minferDictAsStruct()\n\u001b[1;32m    516\u001b[0m prefer_timestamp_ntz \u001b[39m=\u001b[39m is_timestamp_ntz_preferred()\n",
      "\u001b[0;31mValueError\u001b[0m: can not infer schema from empty dataset"
     ]
    }
   ],
   "source": [
    "def generate_new_columns(df):\n",
    "    columns = ['Provincia', 'Canton', 'Distrito','Tasa neta de participación', 'Porcentaje de población económicamente inactiva', 'Relación de dependencia económica']\n",
    "    new_df = spark.createDataFrame(data =[], schema = columns)\n",
    "    Provincia = ''\n",
    "    Canton = ''\n",
    "    counter = 0\n",
    "    for row in df.collect():\n",
    "        if row[0] == '':\n",
    "            if counter == 3:\n",
    "                counter = 0\n",
    "            else:\n",
    "             counter += 1\n",
    "        if counter == 1:\n",
    "            Provincia = row[0]\n",
    "        if counter == 2:\n",
    "            Canton = row[0]\n",
    "        if counter == 3:\n",
    "            new_df = new_df.union(spark.createDataFrame([(Provincia, Canton, row[2], row[3], row[4], row[5])], columns))\n",
    "    return new_df\n",
    "    \n",
    "generate_new_columns(inec_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daf9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to remove column Provincia, cantón y distrito in inec_df\n",
    "def remove_column(df):\n",
    "    df = df.drop('Provincia, cantón y distrito')\n",
    "    return df\n",
    "\n",
    "inec_df = remove_column(inec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d76ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create a new dataframe with inec_df and oij_df when provincia, canton and distrito are equals\n",
    "def join_dataframes(df1,df2):\n",
    "    df = df1.join(df2, (df1.Provincia == df2.ProvinciaUnida) | (df1.Canton == df2.CantonUnido) | (df1.Distrito == df2.DistritoUnido), 'inner')\n",
    "    return df\n",
    "\n",
    "df = join_dataframes(oij_df,inec_df)\n",
    "df.show(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create sql table from dataframe\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "#Save the dataframe in a postgresql database\n",
    "df.write.jdbc(url=\"jdbc:postgresql://localhost:5432/etl\", table=\"etl\", mode=\"overwrite\", properties={\"user\": \"postgres\", \"password\": \"Legolas00\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba89b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the dataframe in csv file\n",
    "df.write.csv(path=\"output.csv\", sep=\",\", header=True,quote='\"',mode=\"overwrite\")\n",
    "df.show(5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
