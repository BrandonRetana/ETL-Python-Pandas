{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2498e772",
   "metadata": {},
   "source": [
    "La siguiente celda se encargara de importar todos los paquetes necesarios para el desarrollo del proyecto. Además, se importa el archivo de configuración de la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51d3e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import ltrim,rtrim,trim,col\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "spark = SparkSession.builder.config(\"spark.jars\", \"postgresql-42.5.1.jar\") \\\n",
    "\t.master(\"local\").appName(\"PySpark_Postgres_test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3875913",
   "metadata": {},
   "source": [
    "En la siguiente celda se encarga de utilizar spark para cargar en dos diferentes dataframes los datos del INEC y el OIJ para despues limpiarlos y unirlos en un solo dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5739b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DATAFRAME FROM CSV FILE\n",
    "oij_df = spark.read.csv( path=\"OIJ.csv\", sep=\";\", header=True,quote='\"',inferSchema=True,)\n",
    "inec_df = spark.read.csv( path=\"INEC.csv\", sep=\";\", header=True,quote='\"',inferSchema=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e379181",
   "metadata": {},
   "source": [
    "En la siguiente celda se encarga de realizar la limpieza de los datos del INEC y el OIJ. Primero se creo una función para remover todos los espacios en blanco al inicio y al final de cada sub celda del data frame utilizando la funcion trim para ello. Ademas se creo una funcio la cual se encarga de pasar todos los caracteres a letras minusculas para poder realizar la busqueda de los datos en el data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29dfe503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------+-------------------+-----------+--------------------+-------------+-----------+------------+---------+----------+-----------+\n",
      "|Delito|  SubDelito|   Fecha|               Hora|    Victima|          SubVictima|         Edad|     Genero|Nacionalidad|Provincia|    Canton|   Distrito|\n",
      "+------+-----------+--------+-------------------+-----------+--------------------+-------------+-----------+------------+---------+----------+-----------+\n",
      "|ASALTO|ARMA BLANCA|6/6/2021|18:00:00 - 20:59:59|   VEHICULO|AUTOMOVIL [VEHICULO]|Mayor de edad|     HOMBRE|  COSTA RICA| san jose|      mora| quitirrisí|\n",
      "|ASALTO|ARMA BLANCA|7/6/2021|12:00:00 - 14:59:59|    PERSONA|    PEATON [PERSONA]|Mayor de edad|     HOMBRE|  COSTA RICA| alajuela|  alajuela|san antonio|\n",
      "|ASALTO|ARMA BLANCA|7/6/2021|15:00:00 - 17:59:59|    PERSONA|    PEATON [PERSONA]| Adulto Mayor|     HOMBRE|   NICARAGUA| san jose|  san jose|   hospital|\n",
      "|ASALTO|ARMA BLANCA|7/6/2021|12:00:00 - 14:59:59|    PERSONA|MENOR DE EDAD [PE...|Menor de edad|      MUJER|  COSTA RICA| alajuela|san carlos|    pocosol|\n",
      "|ASALTO|ARMA BLANCA|9/6/2021|03:00:00 - 05:59:59|EDIFICACION|PANADERIA [EDIFIC...|Mayor de edad|DESCONOCIDO|  COSTA RICA|  heredia|   heredia|    heredia|\n",
      "+------+-----------+--------+-------------------+-----------+--------------------+-------------+-----------+------------+---------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------------------+--------------------------+--------------------------+-----------------+-------------------------+-----------------------------------------------+---------------------------------+\n",
      "|Provincia, cantón y distrito|Población de 15 años y más|Tasa neta de participación|Tasa de ocupación|Tasa de desempleo abierto|Porcentaje de población económicamente inactiva|Relación de dependencia económica|\n",
      "+----------------------------+--------------------------+--------------------------+-----------------+-------------------------+-----------------------------------------------+---------------------------------+\n",
      "|                        null|                      null|                      null|             null|                     null|                                           null|                             null|\n",
      "|                    san josé|                 1 087 315|                        56|             54,1|                      3,5|                                             44|                              1,3|\n",
      "|                        null|                      null|                      null|             null|                     null|                                           null|                             null|\n",
      "|                    san josé|                   225 856|                      56,7|             54,5|                      3,9|                                           43,3|                              1,2|\n",
      "|                        null|                      null|                      null|             null|                     null|                                           null|                             null|\n",
      "+----------------------------+--------------------------+--------------------------+-----------------+-------------------------+-----------------------------------------------+---------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Function to remove spaces from the beginning and end of the string\n",
    "def remove_spaces(df):\n",
    "    for col in df.columns:\n",
    "        if  col == 'Provincia' or col == 'Canton' or col == 'Distrito' or col == 'Provincia, cantón y distrito':\n",
    "            df = df.withColumn(col, trim(col))\n",
    "    return df\n",
    "\n",
    "#Function to parser the string to lowercase\n",
    "def to_lower_case(df):\n",
    "    for col in df.columns:\n",
    "        if  col == 'Provincia' or col == 'Canton' or col == 'Distrito' or col == 'Provincia, cantón y distrito':\n",
    "            df = df.withColumn(col, lower(col))\n",
    "    return df\n",
    "\n",
    "\n",
    "oij_df = remove_spaces(oij_df)\n",
    "inec_df = remove_spaces(inec_df)\n",
    "\n",
    "oij_df = to_lower_case(oij_df)\n",
    "inec_df = to_lower_case(inec_df)\n",
    "\n",
    "oij_df.show(5)\n",
    "inec_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c623bb",
   "metadata": {},
   "source": [
    "En la siguente celda se encuentra una funcion la cual se encarga de revisiar en los dos data frames aquellos datos donde no coinciden los datos de la provincia, canton y distrito. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbdf9bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['desconocido', 'san jose', 'limon', 'pococi', 'rio cuarto', 'guacimo', 'belen', 'la union', 'sarchí', 'desconocido', 'leon cortes', 'poas', 'tarrazu', 'san jose', 'san ramon', 'aserri', 'vasquez de coronado', 'paraiso', 'tilaran', 'canas', 'limon', 'perez zeledon', 'jimenez', 'monteverde', 'tibas', 'sarapiqui', 'escazu', 'santa barbara', 'rio cuarto', 'san jeronimo', 'rio naranjo', 'libano', 'isla del coco', 'para', 'colon', 'guapiles', 'guacimo', 'canalete', 'puraba', 'cajon', 'drake', 'belen', 'rincon de sabanilla', 'belen de nosarita', 'reventazón', 'granja', 'santa lucia', 'desconocido', 'santo tomas', 'jardin', 'agua buena', 'la amistad', 'tarcoles', 'alegria', 'santa maria', 'patarra', 'san sebastian', 'caldera', 'cirri sur', 'cortes', 'san jose de la monta?a', 'palmera', 'pavon', 'canas dulces', 'sanchez', 'llanos de santa lucia', 'rio blanco', 'juan vinas', 'general', 'baru', 'rio azul', 'volcan', 'bahia ballena', 'horquetas', 'rio jimenez', 'ceiba', 'sarchi norte', 'cabeceras', 'dulce nombre de jesus', 'guacima', 'la legua', 'san jose', 'san ramon', 'aserri', 'dos rios', 'mastate', 'guaycara', 'fortuna', 'sarchi sur', 'cobano', 'paramo', 'san cristobal', 'labrador', 'jesus maria', 'angeles', 'curubande', 'jaco', 'tapezco', 'tres rios', 'san nicolas', 'jesus', 'batan', 'paraiso', 'tilaran', 'cachi', 'espiritu santo', 'san andres', 'merecedes', 'canas', 'mansion', 'rio segundo', 'gutierrez braun', 'limon', 'matambu', 'samara', 'tigra', 'lagunillas', 'cure?a', 'mata platano', 'cano negro', 'cairo', 'jimenez', 'asuncion', 'diria', 'monteverde', 'leon xiii', 'la colonia', 'san jose (pizote)', 'jaris', 'turrucares', 'macacoma', 'rodriguez', 'concepcion', 'el chirripo', 'penas blancas', 'monterry', 'sarapiqui', 'bolson', 'escazu', 'los angeles', 'birrisito', 'quitirrisí', 'rio nuevo', 'ipis', 'san joaquin', 'duacari', 'san francisco de dos rios', 'santa barbara', 'santa isabel', 'union', 'changuena', 'bolivar']\n"
     ]
    }
   ],
   "source": [
    "#Function find list the not match values in the dataframes\n",
    "def find_non_matches(df1,df2):\n",
    "    non_matches = []\n",
    "    for col in df1.columns:\n",
    "        if  col == 'Provincia' or col == 'Canton' or col == 'Distrito':\n",
    "            for row in df1.select(col).distinct().collect():\n",
    "                if not df2.filter(df2['Provincia, cantón y distrito'] == row[col]).collect():\n",
    "                    non_matches.append(row[col])\n",
    "    return non_matches\n",
    "\n",
    "non_matches_oij = find_non_matches(oij_df,inec_df)\n",
    "\n",
    "\n",
    "\n",
    "oij_df = remove_spaces(oij_df)\n",
    "inec_df = remove_spaces(inec_df)\n",
    "\n",
    "oij_df = to_lower_case(oij_df)\n",
    "inec_df = to_lower_case(inec_df)\n",
    "\n",
    "nonMatches = find_non_matches(oij_df,inec_df)\n",
    "print(nonMatches)\n",
    "#oij_df.show(5)\n",
    "#inec_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca16b2ba",
   "metadata": {},
   "source": [
    "En la siguiente celda se encarga de reemplazar todos los caracteres especiales del español por caracteres ascii para poder realizar la busqueda de los datos en el data frame. Y que su taza de concidencia sea mayor.Para este trabajo se utilizo la funcionalidad regex_replace de spark. Y asi cada vez que se encuentre un caracter especial se reemplazara por un caracter ascii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3046964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['desconocido', 'sarchí', 'desconocido', 'leon cortes', 'vasquez de coronado', 'monteverde', 'puerto jiménez', 'isla del coco', 'canalete', 'drake', 'reventazón', 'granja', 'desconocido', 'agua buena', 'la amistad', 'caldera', 'cortes', 'san jose de la monta?a', 'palmera', 'general', 'horquetas', 'ceiba', 'cabeceras', 'la legua', 'mastate', 'fortuna', 'labrador', 'tapezco', 'merecedes', 'gutierrez braun', 'matambu', 'tigra', 'lagunillas', 'cure?a', 'mata platano', 'cairo', 'asuncion', 'monteverde', 'puerto jiménez', 'la colonia', 'san jose (pizote)', 'jaris', 'macacoma', 'el chirripo', 'monterry', 'los angeles', 'birrisito', 'quitirrisí', 'santa isabel', 'union']\n"
     ]
    }
   ],
   "source": [
    "#Function to replace the accents in column Provincia, cantón y distrito in inec_df\n",
    "def replace_accents(df):\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'á', 'a'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'é', 'e'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'í', 'i'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'ó', 'o'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'ú', 'u'))\n",
    "    df = df.withColumn('Provincia, cantón y distrito', regexp_replace('Provincia, cantón y distrito', 'ñ', 'n'))\n",
    "    return df\n",
    "\n",
    "inec_df = replace_accents(inec_df)\n",
    "nonMatches = find_non_matches(oij_df,inec_df)\n",
    "print(nonMatches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c12f7",
   "metadata": {},
   "source": [
    "En la siguiente celda se encarga de dividir la columna del dataframe del inec en tres columnas diferentes, una para la provincia, otra para el canton y otra para el distrito. Para esto se creo una funcion que basado en la cantidad espacios que se encuentren en la columna se dividira en tres columnas diferentes. Esto para que la comparacion de los datos sea mas exacta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0ffe418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_columns(df):\n",
    "    columns = [\"Provincia1\", \"Canton1\", \"Distrito1\",\"Tasa neta de participación\", \"Porcentaje de población económicamente inactiva\", \"Relación de dependencia económica\"]\n",
    "    new_df = spark.createDataFrame(data =[(\"\",\"\",\"\",\"\",\"\",\"\")], schema = columns)\n",
    "    Provincia =''\n",
    "    Canton = ''\n",
    "    Distrito = ''\n",
    "    counter = 0\n",
    "    counter2 = 0\n",
    "    for row in df.collect():\n",
    "        if row['Provincia, cantón y distrito'] == None:\n",
    "            counter += 1\n",
    "            counter2 += 1\n",
    "            if counter == 4: \n",
    "                counter = 2  \n",
    "\n",
    "            if counter2 == 2:\n",
    "                counter = 1\n",
    "            continue\n",
    "        if counter == 1:\n",
    "            Provincia = row[0]\n",
    "        if counter == 2:\n",
    "            Canton = row[0]\n",
    "        if counter == 3:\n",
    "            Distrito = row[0]\n",
    "            NewRow = (Provincia, Canton, Distrito, \"\", \"\", \"\")\n",
    "            new_df = new_df.union(spark.createDataFrame(data =[NewRow], schema = columns))\n",
    "        counter2 = 0\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "new_df = generate_new_columns(inec_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0085bc82",
   "metadata": {},
   "source": [
    "Esta funcion todavia no se si se deberia utilizar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d76ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "239e2ce8",
   "metadata": {},
   "source": [
    "En la siguiente celda se encarga de la conexion a la base de datos y la creacion de las tablas necesarias para el almacenamiento de los datos ya limpios y procesados. Se crean dos tablas una para el inec y otra para el oij."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create sql table from dataframe\n",
    "url = \"jdbc:postgresql://localhost:5432/etl\"\n",
    "mode = \"overwrite\"\n",
    "properties = {\"user\": \"postgres\", \" password\": \"Legolas00\", \"driver\": \"org.postgresql.Driver\"}\n",
    "\n",
    "new_df.write.jdbc(url=url, table=\"INEC\", mode=mode, properties=properties)\n",
    "oij_df.write.jdbc(url=url, table=\"OIJ\", mode=mode, properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba89b29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
